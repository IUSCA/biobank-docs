# Biobank System Architecture

## High-Level System Architecture

```mermaid
graph TB
    %% Main Application Cluster
    subgraph "Main Application"
        direction TB
        Proxy[ğŸŒ Nginx Reverse Proxy]
        
        subgraph "Frontend"
            UI[ğŸ–¥ï¸ Vue.js UI<br/>Port 443]
        end
        
        subgraph "Backend Services"
            API[âš¡ Express.js API<br/>Port 3030]
            SecureDownload[ğŸ”’ Secure Download Service<br/>Node.js]
        end
        
        subgraph "Database Layer"
            PostgresMain[(ğŸ—ƒï¸ PostgreSQL<br/>Main Database<br/>Port 5432)]
        end
    end

    %% Worker Services Cluster
    subgraph "Worker Services"
        direction TB
        CeleryWorkers[ğŸ”„ Celery Workers<br/>Python]
        FileServer[ğŸ“ Nginx File Server]
        
        subgraph "Worker Infrastructure"
            RabbitMQ[(ğŸ° RabbitMQ<br/>Message Queue)]
            MongoDB[(ğŸƒ MongoDB<br/>Result Backend)]
        end
    end

    %% Core Services (External Dependencies)
    subgraph "Core Services"
        direction TB
        RhythmAPI[ Rhythm API<br/>FastAPI]
        AuthService[ğŸ”‘ Signet Auth<br/>Flask]
    end

    %% External Users and Systems
    subgraph "External"
        Users[ğŸ‘¥ Researchers & Analysts]
        HPFS[ğŸ—„ï¸ HPFS Storage]
        SDA[ğŸ—„ï¸ SDA Storage]
        ScratchStorage[ğŸ’¾ Slate Scratch Storage]
        CAS[ğŸ” CAS Authentication]
        ExtData[ğŸ“Š External Genomic Data]
    end


    %% User Interactions
    Users --> Proxy
    Proxy --> UI
    UI --> API
    
    %% Authentication Flow
    Users --> CAS
    CAS --> AuthService
    AuthService --> RhythmAPI
    
    %% API Connections
    API --> PostgresMain
    API --> RhythmAPI
    API <--> CeleryWorkers
    
    %% Worker Connections
    CeleryWorkers --> RabbitMQ
    CeleryWorkers --> MongoDB
    CeleryWorkers --> ScratchStorage
    CeleryWorkers --> HPFS
    CeleryWorkers --> SDA
    
    %% Data Ingestion
    ExtData --> CeleryWorkers
    
    %% File Access
    UI --> FileServer
    FileServer --> SecureDownload
    FileServer --> ScratchStorage
    
    %% Core Service Connections
    RhythmAPI --> RabbitMQ
    RhythmAPI --> MongoDB

    %% Styling
    classDef frontend fill:#e1f5fe
    classDef backend fill:#f3e5f5
    classDef database fill:#e8f5e8
    classDef worker fill:#fff3e0
    classDef external fill:#fce4ec
    classDef storage fill:#f1f8e9
    
    class UI frontend
    class API,SecureDownload backend
    class PostgresMain,MongoDB,RabbitMQ database
    class CeleryWorkers,FileServer worker
    class Users,HPFS,SDA,CAS,ExtData,RhythmAPI,AuthService external
    class ScratchStorage storage
```

## Data Flow Architecture

```mermaid
graph LR
    %% Data Ingestion Flow
    subgraph "Data Ingestion Pipeline"
        direction TB
        A[ğŸ“Š Raw Genomic Data] --> B[ğŸ”„ Celery Workers]
        B --> C[âœ… Data Validation]
        C --> D[ğŸ§¬ Variant Processing]
        D --> E[ğŸ“ Annotation Enrichment]
        E --> F[(ğŸ—ƒï¸ PostgreSQL Storage)]
        F --> G[ğŸ“Š Statistics Generation]
        G --> H[ğŸ” Search Indexing]
    end

    %% Cohort Query Flow
    subgraph "Cohort Building Pipeline"
        direction TB
        I[ğŸ–¥ï¸ Query Builder UI] --> J[ğŸ“‹ Query Validation]
        J --> K[ğŸ”§ SQL Generation]
        K --> L[âš¡ Database Execution]
        L --> M[ğŸ’¾ Result Caching]
        M --> N[ğŸ“ˆ Visualization]
    end

    %% File Access Flow
    subgraph "Secure File Access"
        direction TB
        O[ğŸ‘¤ User Request] --> P[ğŸ” Authentication]
        P --> Q[âœ… Authorization Check]
        Q --> R[ğŸ« Token Generation]
        R --> S[ğŸ“ File Server]
        S --> T[ğŸ“¥ Secure Download]
    end
```

## Database Schema Overview

```mermaid
erDiagram
    %% Core Entities
    USER ||--o{ COHORT : creates
    USER ||--o{ PROJECT : participates
    USER ||--o{ DATASET_AUDIT : logs
    
    %% Participant Data
    PARTICIPANT ||--o{ DEMOGRAPHIC : has
    PARTICIPANT ||--o{ LAB : has
    PARTICIPANT ||--o{ DX : has
    PARTICIPANT ||--o{ MEDICATION : has
    PARTICIPANT ||--o{ HOSPITAL : has
    PARTICIPANT ||--o{ COVID_TEST : has
    PARTICIPANT ||--o{ COVID_VAX : has
    
    %% Genomic Data
    SOURCE ||--o{ VARIANT : contains
    SNAPSHOT ||--o{ GENOTYPE_SET : includes
    GENOTYPE_SET ||--o{ GENOTYPE_FILE : contains
    GENOTYPE_SET ||--o{ GENOTYPE_SAMPLE : includes
    
    %% Cohort System
    COHORT {
        uuid id PK
        string name
        json query
        int[] participants
        boolean is_published
        boolean is_locked
        boolean is_protected
        boolean is_temp
    }
    
    %% Variant Analysis
    VARIANT {
        int chr PK
        bigint position PK
        string ref PK
        string alt PK
        int source_id PK
        boolean phase
        int[] genotype
    }
    
    ANNOTATION {
        int chr PK
        bigint position PK
        string ref PK
        string alt PK
        string func
        string[] genes
        float af_nfe
        string cln_sig
    }
    
    %% Data Management
    DATASET ||--o{ DATASET_FILE : contains
    DATASET ||--o{ WORKFLOW : processes
    PROJECT ||--o{ DATASET : includes
```

## Service Communication Patterns

```mermaid
sequenceDiagram
    participant U as User
    participant UI as Vue.js UI
    participant API as Express API
    participant DB as PostgreSQL
    participant W as Celery Workers
    participant Q as RabbitMQ
    participant FS as File Server

    %% Cohort Creation Flow
    Note over U,FS: Cohort Creation Workflow
    U->>UI: Build Query
    UI->>API: POST /cohorts
    API->>DB: Validate Query Schema
    API->>DB: Generate SQL
    API->>DB: Execute Query
    DB-->>API: Participant IDs
    API->>DB: Store Cohort
    API-->>UI: Cohort Created
    UI-->>U: Show Results

    %% Data Processing Flow
    Note over U,FS: Data Processing Workflow
    U->>UI: Upload Dataset
    UI->>API: POST /datasets
    API->>Q: Queue Processing Task
    Q->>W: Process Dataset
    W->>DB: Store Processed Data
    W->>Q: Update Status
    Q-->>API: Task Complete
    API-->>UI: Processing Complete
    UI-->>U: Dataset Ready

    %% File Download Flow
    Note over U,FS: Secure File Access
    U->>UI: Request File
    UI->>API: GET /files/{id}
    API->>DB: Check Permissions
    API-->>UI: Download Token
    UI->>FS: Download with Token
    FS-->>UI: File Stream
    UI-->>U: File Downloaded
```


## Deployment Architecture

```mermaid
graph TB
    subgraph "Docker Compose Environment"
        direction TB
        
        subgraph "Application Containers"
            UIContainer[ğŸ³ UI Container<br/>node:19<br/>Vite Dev Server]
            APIContainer[ğŸ³ API Container<br/>node:19<br/>Express + Prisma]
        end
        
        subgraph "Database Containers"
            PostgresContainer[ğŸ³ PostgreSQL Container<br/>postgres:14.5<br/>Partitioned Tables]
        end
        
        subgraph "External Services"
            WorkerServices[ğŸ”„ Python Workers<br/>Poetry + Celery]
            SecureDownloadService[ğŸ”’ Secure Download<br/>Node.js Service]
        end
        
        subgraph "Volumes"
            UIModules[ğŸ“¦ ui_modules]
            APIModules[ğŸ“¦ api_modules]
            DBData[ğŸ’¾ PostgreSQL Data]
        end
    end
    
    subgraph "Host Network"
        LocalHost[ğŸ–¥ï¸ localhost:443 â†’ UI]
        APIHost[âš¡ localhost:3030 â†’ API]
        DBHost[ğŸ—ƒï¸ localhost:5432 â†’ DB]
    end
    
    UIContainer --> UIModules
    APIContainer --> APIModules
    PostgresContainer --> DBData
    
    LocalHost --> UIContainer
    APIHost --> APIContainer
    DBHost --> PostgresContainer
